\section{Conclusion}
Large HPC centers are increasingly facing 
multifaceted resource and job management challenges
that if not properly met, will result 
in significant losses.  
We present a new management paradigm and its incarnation, \flux, that can effectively
address these challenges in a single software framework,
%\flux is our response to embody this paradigm 
%so as to improve operational efficiency 
%and user productivity and to change
%the fundamental 
while making site-wide operations more tractable.
%and help change the way in which large centers are managed.
%Our run-time infrastructure such as CMB and KVS
%is a significant first step to this rather long
%journey.

We have validated two of the key run-time components responsible for communication,
% aspects of these
%components to guide our future efforts systematically. 
and our results show that our run-time 
infrastructure is most scalable when information 
exchange patterns themselves are also scalable, which suggests two significant directions. 
For one, we must carefully design the data exchange patterns
among distributed components of run-time elements including \flux's own management services. 
In particular, to achieve extreme scalability, each component 
must avoid accessing a global view.
Secondly, we must also continue to push the 
scalability envelope of our infrastructure, in particular in the
KVS. We plan to address the latter by 
distributing the KVS master itself.
%For the latter, we will soon investigate a way to 
%shard KVS masters into multiple nodes
%and to distribute access patterns to further improve scalability.
%
%Besides scalability, we must also address KVS persistency.
%Specifically, we plan to explore a scheme
%thereby putting on-disk cache behind the KVS master,
%and then temporally expire the master's cache.
%In fact, we will investigate ways to link
%this scheme to the sharding scheme such a way
%that a single on-disk cache can service the value
%objects to all of the KVS masters.

%There are other deficiencies we must address as well.
%These include network security and
%comprehensive fault tolerance. 
%As we continue to implement these building blocks 
%to further our framework, we will be evaluating 
%whether the framework can meet our goal for \flux's 
%flexibility, scalability, and extensibility. 
Ultimately, we are designing \flux to  
enable developers at the operating system and
run-time levels to leverage the RJMS data stores and services in
new and powerful ways, and we expect that it will position HPC centers to cope
with diverse, massively large-scale resources.
