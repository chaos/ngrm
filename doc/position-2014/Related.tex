\section{Related Work}
Our work seeks to change the paradigm in which 
how the RM manages, models, schedules, and
allocates its resources. Much research exists in
each of these areas including commercial offerings
such as Slurm~\cite{Jette02slurm}, LCF, 
Moab and PBS Professional~\cite{PSBPro}.
The commercial products provide traditional paradigms, and
most research work offers 
point solutions. In fact, \flux\ came out of real-world needs 
for a comprehensive production open-source RM that embodies a new paradigm. 

HPC trends increasingly motivate scalable KVS implementations 
like ours. Wang et al. proposed using a distributed KVS 
as the basis for HPC tools and services to encapsulate
complexity of distributed services in the KVS~\cite{Wang:2013:USE:2503210.2503239}.
%
%, thereby simplifying the
%tools and services~\cite{Wang:2013:USE:2503210.2503239}.
They further evaluate replacing the centralized controller in
Slurm~\cite{Jette02slurm} with a distributed controller~\cite{Slurmpp}
built on ZHT~\cite{Li:2013:ZLR:2510661.2511401}.
While existing KVS work takes an incremental approach of improving 
scalability of a traditional RM paradigm with new scalable services,
ours are built specifically to support the new paradigm. 

We also evaluated Redis~\cite{Redis} and twemproxy~\cite{Twemproxy}
as part of our early KVS investigations.
In particular, Redis cluster~\cite{RedisClusterTut,RedisClusterSpec} 
includes many desired properties such as 
sharding, re-sharding, replication, and failover.
However, their design points are not optimized
for HPC workloads which often feature synchrony and coordination. 
Our consistency model and mechanisms such as the collective fence 
specifically optimized for HPC.


%There is no proxy; clients connect directly to the server
%for a particular shard.  Redis-cluster's asynchronous replication
%results in the possibility of losing writes that occur during failover.
%
Finally, much research exists in the area of tree-based overlay network (TBON). 
They include MRNet~\cite{mrnet} and COBO~\cite{launchmon}, and 
%In particular, MRNet is a reusable designed to be embedded 
%in large scale HPC tools such as STAT~\cite{STAT}. 
%%They have explored
%{\em state compensation}~\cite{conf/ipps/ArnoldM10}
%as a mechanism for fault tolerance in TBONs that perform data aggregation.
CMB can be considered to be a TBON. But unlike user-level
TBONs, ours must support system-level activities, and this 
requires us to answer distinct research topics
such as support for multiple user-level networks (which actually
include other user-level overlay networks), security, low noise 
and fault tolerance. 

