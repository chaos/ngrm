\section{A New Management Paradigm for HPC}
\label{label:paradigm}
HPC centers typically provide a wide range of 
platforms on which scientific applications perform
computations.
The RJMS system is responsible for efficiently delivering 
compute cycles of these platforms
to multiple users who must submit jobs to run their applications. 
Thus, the RJMS matches the users' job request with the available 
resources and provides efficient functions 
for building, submitting, launching, 
and monitoring jobs~\cite{GeorgiouThesis}. 
Typically, an HPC center runs an RJMS instance~\cite{Jette02slurm} 
to manage and schedule an individual system (e.g., cluster) and 
additionally employs separate grid software to tie 
these instances together. 

However, several growing trends present major challenges 
to this current management paradigm. 
First, systems sited at one center are growing larger 
and types of resources are becoming increasingly diverse~\cite{GeorgiouThesis}. 
%The RJMS must now provide  
%extreme scalability, low
%noise, fault tolerance, and heterogeneity management
%to most of the resources sited across the entire center. 
Second, interplays between 
various classes of resources
(e.g., between compute clusters and a global file system)
are becoming more complicated and disruptive~\cite{SCR,SPINDLE}. 
Third, resource constraints are also becoming increasingly
complex in a multidimensional, dynamic, and hierarchical fashion~\cite{power-overprovision}
(e.g., dynamic power capping at the level of systems, compute racks, and/or nodes).
Further, the need for code-development tools and their requirements on tool launching and job access
impose challenging requirements on the RJMS~\cite{STAT,SPINDLE,PRUNER,SCR,launchmon}.
Finally, the workloads themselves are becoming 
diverse, dynamic, and large, and are moving away from individual monolithic jobs. Instead,
ensembles of jobs, e.g., for Uncertainty Quantification 
%DONG: We need a refernece to use Scalebriging Application
or Scalebriding Applications, are becoming increasingly commonplace.

To address the issues effectively,
large HPC centers demand a new resource and job management paradigm.
The new paradigm must increase its purview and 
scalably manage resources across the entire center.
Perhaps more importantly, it must be implemented under one common 
RJMS framework so that its schedulers can make use of
its full resource representations.
Only this allows centers to (co-)schedule jobs 
effectively to various types of resources and to
provide much richer provenance on jobs (e.g., correlation between
a user-level error and other system activities). 
%A divide-and-conquer approach will enable the RJMS 
%to scale to the entire center. 
The new paradigm, however,
creates a series of challenges a new RJMS must overcome:

%It is important to note that all of these must 
%be enabled by one common RJMS framework. 
%The current paradigm of loosely coupling different software 
%(i.e., grid software with cluster-wide RJMS instances) 
%leads to a loss of important system knowledge
%needed for effective resource and job management and scheduling. 
%Different software employ distinct resource and
%job representations and key data are often lost in translation.
%Also, the single common framework can offer 
%common run-time commonents as a backbone of
%supporting hierarchical management of resources and jobs
%in a highly scalable, fault-tolerant, secure and customizable
%manner.

%We realize that embodying the new paradigm is non-trivial, as
%the following characterizes the challenges it must address.

\noindent{\em Challenge 1: Multidimensional Scaling --- } 
The new paradigm requires that the RJMS can impose
complex, multidimensional resource bounds at any scale, 
from the center-wide level, down to the level of individual processes,
and enable the most efficient execution and
scheduling of workloads within these bounds.
This imposes unprecedented scale challenges
in multiple dimensions, including
%We generally characterize this challenge 
%as the {\em multidimensional scale} challenge. The challenges
% include
supporting extreme scalability, addressing noise as concurrency
increases, and managing a drastically increased amount of
run-time information that must be monitored, traced, and stored.
The new paradigm must efficiently handle increased scale in
numbers of resources as well as jobs and other dimensions 
of RJMS data.

\noindent{\em Challenge 2: Diverse workloads --- }
HPC applications are known to have disparate performance 
limiting factors. This requires
the new paradigm to have a rich resource model, including
the 
%This includes a 
representation for diverse
types of resources such as file systems, networks, visualization
hardware, and heterogeneous compute engines.
With a richer resource model, the RJMS will be capable of imposing
complex, multidimensional resource bounds, as opposed to the
simplistic traditional resource model that is fundamentally based on a
flat list of nodes, and allowing it to 
%With the ability to model sophisticated resource relationships,
%the new paradigm will be able to schedule and
allocate resources tailored to the disparate limiting
factors of HPC applications.  

\noindent{\em Challenge 3: Dynamic Workloads --- }
Resource allocations
must be elastic, i.e., resource allocations must be able to grow and shrink
dynamically. This is necessary to support HPC applications with different
phases with disparate performance-limiting factors.
Different resource types have different
elastic properties 
(e.g., power is a much more elastic resource than compute nodes)
restricting decision points and allocation granularity.
%HPC applications and their programming models are
%becoming increasingly dynamic with different multi-resource requirements
%at different phases. 
One consequence of this is that the RJMS must 
support multiple levels of elasticity 
as a function of dynamically changing performance limiters
as well as their limiting resource types---e.g., 
rigid vs. moldable vs. malleable scheduling~\cite{Convergence} 
against different workload and resource types.

\noindent{\em Challenge 4: Productivity --- }
The new paradigm must address increasing complexities
in code development and system administration by facilitating
the creation of more effective diagnostic and analysis tools.
For example, it must provide basic, scalable monitoring and communication
primitives at the job level that can be leveraged by tools.
It will encourage a richer, stronger tool ecosystem.
% where
%these basic but non-trivial capabilities need not be recreated
%from scratch in every tool, reducing development costs.
Better tools will lead to higher productivity for all
stakeholders, including end users.
%We characterize this design challenge as the {\em productivity challenge}.

\noindent{\em System Challenges --- }
In addition to these main requirements that come from the user side
of the RJMS, we also face internal challenges that need to be hidden
from the user. 
%We have considered additional challenges. 
For example, in a global model,
the risk of higher downtime costs arises. 
%in a more global model.
If the RJMS is inadequately designed, a downtime could negatively
impact the availability of a large portion of the center's
resources. Thus, it must be tolerant of hardware and software
faults and failures and have no single point of failure as well as 
support live software upgrades. 
Other challenges include security, integration risk, 
and backwards compatibility. 
%will be addressed in our future work.

%

This series of challenges strongly motivates 
a specific management and scheduling scheme:
the new RJMS must hierarchically and dynamically
manage and schedule the resources under one
common software framework. The divide-and-conquer
approach will then allow the RJMS to scale to massive
amounts of resources sited at a large center.  
%Undoubtedly, such a new paradigm will face unprecedented scaling challenges.
%in job scheduling. a RJMS 
%Thus, it 
Further, the hierarchical, multilevel job scheduling
will then facilitate scheduler parallelism~\cite{Omega,Mesos},
and this will allow the RJMS to scale to massive numbers
of jobs scheduled across the center.
In this scheme, higher-level schedulers
must allow a site to impose site-wide policies, contracts,
and constraints while lower-level schedulers should allow
efficient use of any subsets of resources in accordance with
workload types.
Finally, the RJMS must be capable of dynamically supporting
arbitrarily deep levels in this management and scheduler 
hierarchy with an ability to impose
different constraints at each level.


